{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc40677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy.interpolate import interp1d\n",
    "from os.path import dirname, join as pjoin\n",
    "import os\n",
    "import io\n",
    "import scipy.io as sio\n",
    "import urllib\n",
    "from neuralop import Trainer\n",
    "from neuralop.losses.data_losses import LpLoss\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76e97d",
   "metadata": {},
   "source": [
    "# データダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d28c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_moments(root=\"../vlasov_random_data\",max_cases=None):\n",
    "    \"\"\"\n",
    "    root 以下の data_XXXX/moments.npz を全部読み込んで\n",
    "    X: (Nsamples, 3, N), Y: (Nsamples, 1, N) を作る\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "\n",
    "    # data_0000, data_0001, ... を全部拾う\n",
    "    folders = sorted(glob.glob(os.path.join(root, \"data_*\")))\n",
    "    total = len(folders)\n",
    "\n",
    "    if max_cases is not None:\n",
    "        folders = folders[:max_cases]   # ← 指定数だけフォルダを使う\n",
    "\n",
    "    print(f\"Found {total} folders, loading {len(folders)} folders\")\n",
    "\n",
    "\n",
    "    for idx, folder in enumerate(folders):\n",
    "        path = os.path.join(folder, \"moments.npz\")\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "\n",
    "        d = np.load(path)\n",
    "        n = d[\"n\"]\n",
    "        u = d[\"u\"]\n",
    "        p = d[\"p\"]\n",
    "        dn_dx = d[\"dn_dx\"]\n",
    "        du_dx = d[\"du_dx\"]\n",
    "        dp_dx = d[\"dp_dx\"]\n",
    "        dq = d[\"dq_dx\"]\n",
    "\n",
    "        # すぐ torch tensor に変換\n",
    "        X = torch.tensor(np.stack([n,u,p,dn_dx,du_dx,dp_dx],axis=1), dtype=torch.float32)\n",
    "        Y = torch.tensor(dq[:,None,:], dtype=torch.float32)\n",
    "\n",
    "        X_list.append(X)\n",
    "        Y_list.append(Y)\n",
    "\n",
    "        # プログレス表示\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"  loading... {idx}/{len(folders)}\")\n",
    "\n",
    "    # torch.cat で結合（高速 & メモリ節約）\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    Y = torch.cat(Y_list, dim=0)\n",
    "\n",
    "    print(\"Done loading:\", X.shape, Y.shape)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f9328",
   "metadata": {},
   "source": [
    "# パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165bfef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "batch_size = 32 # バッチサイズ\n",
    "num_epoch = 30 # エポック数\n",
    "num_modes = 16 # フーリエ空間で使用するモードの数\n",
    "num_channels = 64 # インプットとアウトプットの間の層の数\n",
    "in_channels = 6 # インプット数\n",
    "device = 'cuda'\n",
    "root=\"../vlasov_random_data\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77e87",
   "metadata": {},
   "source": [
    "# データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1194c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_apply_scaler(X, Y, save_path=\"scaler.npz\"):\n",
    "    \"\"\"\n",
    "    X: (Nsamp, 3, N)\n",
    "    Y: (Nsamp, 1, N)\n",
    "    学習時の平均・標準偏差を計算し、保存＆正規化した X,Y を返す\n",
    "    \"\"\"\n",
    "    # チャネルごとに flatten して mean/std\n",
    "    mu_n = X[:, 0, :].mean()\n",
    "    sig_n = X[:, 0, :].std()\n",
    "    mu_u = X[:, 1, :].mean()\n",
    "    sig_u = X[:, 1, :].std()\n",
    "    mu_p = X[:, 2, :].mean()\n",
    "    sig_p = X[:, 2, :].std()\n",
    "    mu_dn = X[:, 3, :].mean()\n",
    "    sig_dn = X[:, 3, :].std()\n",
    "    mu_du = X[:, 4, :].mean()\n",
    "    sig_du = X[:, 4, :].std()\n",
    "    mu_dp = X[:, 5, :].mean()\n",
    "    sig_dp = X[:, 5, :].std()\n",
    "\n",
    "    mu_dq = Y[:, 0, :].mean()\n",
    "    sig_dq = Y[:, 0, :].std()\n",
    "\n",
    "    # 保存\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        mu_n=mu_n, sig_n=sig_n,\n",
    "        mu_u=mu_u, sig_u=sig_u,\n",
    "        mu_p=mu_p, sig_p=sig_p,\n",
    "        mu_dn=mu_dn, sig_dn=sig_dn,\n",
    "        mu_du=mu_du, sig_du=sig_du,\n",
    "        mu_dp=mu_dp, sig_dp=sig_dp,\n",
    "        mu_dq=mu_dq, sig_dq=sig_dq,\n",
    "    )\n",
    "\n",
    "    # 正規化\n",
    "    X_norm = np.empty_like(X, dtype=np.float32)\n",
    "    Y_norm = np.empty_like(Y, dtype=np.float32)\n",
    "\n",
    "    X_norm[:, 0, :] = (X[:, 0, :] - mu_n) / sig_n\n",
    "    X_norm[:, 1, :] = (X[:, 1, :] - mu_u) / sig_u\n",
    "    X_norm[:, 2, :] = (X[:, 2, :] - mu_p) / sig_p\n",
    "    X_norm[:, 3, :] = (X[:, 3, :] - mu_dn) / sig_dn\n",
    "    X_norm[:, 4, :] = (X[:, 4, :] - mu_du) / sig_du\n",
    "    X_norm[:, 5, :] = (X[:, 5, :] - mu_dp) / sig_dp\n",
    "\n",
    "    Y_norm[:, 0, :] = (Y[:, 0, :] - mu_dq) / sig_dq\n",
    "\n",
    "    return X_norm, Y_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b830ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VlasovClosureDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        # X: (Nsamp, 6, N), Y: (Nsamp, 1, N) (float32想定)\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.Y = torch.from_numpy(Y.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f466926",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00159cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    def l2loss(pred, **sample):\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        return criterion(pred, sample[\"y\"])\n",
    "\n",
    "else:\n",
    "    #\n",
    "    l2loss = LpLoss(d=1, p=2, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b0d4e",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fno_model(n_modes=16, hidden_channels=64, n_layers=4, N_grid=64):\n",
    "    \"\"\"\n",
    "    1D FNO モデルを構築\n",
    "    \"\"\"\n",
    "    model = FNO(\n",
    "        n_modes=(n_modes,),     # 1次元なので tuple で (n_modes,)\n",
    "        hidden_channels=num_channels,\n",
    "        in_channels=3,\n",
    "        out_channels=1,\n",
    "        n_layers=n_layers,\n",
    "        max_n_modes=(N_grid,),  # グリッド数（通常は N）\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5023d",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c778d",
   "metadata": {},
   "source": [
    "データ読み込みと正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf68b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- データ読み込み ----------\n",
    "X, Y = load_all_moments(root=root,max_cases=300)\n",
    "\n",
    "# ---------- 正規化 ----------\n",
    "X_norm, Y_norm = compute_and_apply_scaler(X, Y, save_path=\"/content/drive/MyDrive/deep_learning/basic/machine_learning/scaler_random3.npz\")\n",
    "print(\"After normalization: X\", X_norm.shape, \"Y\", Y_norm.shape)\n",
    "\n",
    "# ---------- Dataset & split ----------\n",
    "full_dataset = VlasovClosureDataset(X_norm, Y_norm)\n",
    "\n",
    "N_total = len(full_dataset)\n",
    "N_train = int(0.8 * N_total)\n",
    "N_val   = int(0.1 * N_total)\n",
    "N_test  = N_total - N_train - N_val\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_dataset, [N_train, N_val, N_test])\n",
    "print(f\"Dataset split: train={N_train}, val={N_val}, test={N_test}\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b357e12",
   "metadata": {},
   "source": [
    "モデル, optimizer, loss_fnの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- モデル構築 ----------\n",
    "N_grid = X.shape[-1]\n",
    "model = build_fno_model(\n",
    "    n_modes=16,\n",
    "    hidden_channels=64,\n",
    "    n_layers=4,\n",
    "    N_grid=N_grid\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# ---------- オプティマイザ・損失 ----------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55516c4b",
   "metadata": {},
   "source": [
    "学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a36bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 学習ループ ----------\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)        # (B,3,N)\n",
    "        yb = yb.to(device)        # (B,1,N)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(xb)        # (B,1,N) を想定\n",
    "        loss = loss_fn(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # ---------- 検証 ----------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            y_pred = model(xb)\n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"[{epoch+1:02d}/{num_epochs}] train_loss={train_loss:.4e}, val_loss={val_loss:.4e}\")\n",
    "torch.save(model.state_dict(), \"FNOmodel_from_vlasov_random.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
