{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bc40677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n",
    "from neuralop.training import AdamW\n",
    "from neuralop.utils import count_model_params\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy.interpolate import interp1d\n",
    "from os.path import dirname, join as pjoin\n",
    "import os\n",
    "import io\n",
    "import scipy.io as sio\n",
    "import urllib\n",
    "from neuralop import Trainer\n",
    "from neuralop.losses.data_losses import LpLoss\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76e97d",
   "metadata": {},
   "source": [
    "# データダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92d28c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_moments(root=\"../vlasov_random_data\",max_cases=None):\n",
    "    \"\"\"\n",
    "    root 以下の data_XXXX/moments.npz を全部読み込んで\n",
    "    X: (Nsamples, 3, N), Y: (Nsamples, 1, N) を作る\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    Y_list = []\n",
    "\n",
    "    # data_0000, data_0001, ... を全部拾う\n",
    "    folders = sorted(glob.glob(os.path.join(root, \"data_*\")))\n",
    "    total = len(folders)\n",
    "\n",
    "    if max_cases is not None:\n",
    "        folders = folders[:max_cases]   # ← 指定数だけフォルダを使う\n",
    "\n",
    "    print(f\"Found {total} folders, loading {len(folders)} folders\")\n",
    "\n",
    "\n",
    "    for idx, folder in enumerate(folders):\n",
    "        path = os.path.join(folder, \"moments.npz\")\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "\n",
    "        d = np.load(path)\n",
    "        n = d[\"n\"]\n",
    "        u = d[\"u\"]\n",
    "        p = d[\"p\"]\n",
    "        dn_dx = d[\"dn_dx\"]\n",
    "        du_dx = d[\"du_dx\"]\n",
    "        dp_dx = d[\"dp_dx\"]\n",
    "        dq = d[\"dq_dx\"]\n",
    "\n",
    "        # すぐ torch tensor に変換\n",
    "        X = torch.tensor(np.stack([n,u,p,dn_dx,du_dx,dp_dx],axis=1), dtype=torch.float32)\n",
    "        Y = torch.tensor(dq[:,None,:], dtype=torch.float32)\n",
    "\n",
    "        X_list.append(X)\n",
    "        Y_list.append(Y)\n",
    "\n",
    "        # プログレス表示\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"  loading... {idx}/{len(folders)}\")\n",
    "\n",
    "    # torch.cat で結合（高速 & メモリ節約）\n",
    "    X = torch.cat(X_list, dim=0)\n",
    "    Y = torch.cat(Y_list, dim=0)\n",
    "\n",
    "    print(\"Done loading:\", X.shape, Y.shape)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f9328",
   "metadata": {},
   "source": [
    "# パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165bfef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0+cu128\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# パラメータ\n",
    "batch_size = 32 # バッチサイズ\n",
    "num_epoch = 30 # エポック数\n",
    "num_modes = 16 # フーリエ空間で使用するモードの数\n",
    "num_channels = 64 # インプットとアウトプットの間の層の数\n",
    "in_channels = 6 # インプット数\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "root=\"../vlasov_random_data\"\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d77e87",
   "metadata": {},
   "source": [
    "# データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1194c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_apply_scaler(X, Y, save_path=\"scaler.npz\"):\n",
    "    \"\"\"\n",
    "    X: (Nsamp, 3, N)\n",
    "    Y: (Nsamp, 1, N)\n",
    "    学習時の平均・標準偏差を計算し、保存＆正規化した X,Y を返す\n",
    "    \"\"\"\n",
    "    # チャネルごとに flatten して mean/std\n",
    "    mu_n = X[:, 0, :].mean()\n",
    "    sig_n = X[:, 0, :].std()\n",
    "    mu_u = X[:, 1, :].mean()\n",
    "    sig_u = X[:, 1, :].std()\n",
    "    mu_p = X[:, 2, :].mean()\n",
    "    sig_p = X[:, 2, :].std()\n",
    "    mu_dn = X[:, 3, :].mean()\n",
    "    sig_dn = X[:, 3, :].std()\n",
    "    mu_du = X[:, 4, :].mean()\n",
    "    sig_du = X[:, 4, :].std()\n",
    "    mu_dp = X[:, 5, :].mean()\n",
    "    sig_dp = X[:, 5, :].std()\n",
    "\n",
    "    mu_dq = Y[:, 0, :].mean()\n",
    "    sig_dq = Y[:, 0, :].std()\n",
    "\n",
    "    # 保存\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        mu_n=mu_n, sig_n=sig_n,\n",
    "        mu_u=mu_u, sig_u=sig_u,\n",
    "        mu_p=mu_p, sig_p=sig_p,\n",
    "        mu_dn=mu_dn, sig_dn=sig_dn,\n",
    "        mu_du=mu_du, sig_du=sig_du,\n",
    "        mu_dp=mu_dp, sig_dp=sig_dp,\n",
    "        mu_dq=mu_dq, sig_dq=sig_dq,\n",
    "    )\n",
    "\n",
    "    # 正規化\n",
    "    X_norm = np.empty_like(X, dtype=np.float32)\n",
    "    Y_norm = np.empty_like(Y, dtype=np.float32)\n",
    "\n",
    "    X_norm[:, 0, :] = (X[:, 0, :] - mu_n) / sig_n\n",
    "    X_norm[:, 1, :] = (X[:, 1, :] - mu_u) / sig_u\n",
    "    X_norm[:, 2, :] = (X[:, 2, :] - mu_p) / sig_p\n",
    "    X_norm[:, 3, :] = (X[:, 3, :] - mu_dn) / sig_dn\n",
    "    X_norm[:, 4, :] = (X[:, 4, :] - mu_du) / sig_du\n",
    "    X_norm[:, 5, :] = (X[:, 5, :] - mu_dp) / sig_dp\n",
    "\n",
    "    Y_norm[:, 0, :] = (Y[:, 0, :] - mu_dq) / sig_dq\n",
    "\n",
    "    return X_norm, Y_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b830ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VlasovClosureDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        # X: (Nsamp, 6, N), Y: (Nsamp, 1, N) (float32想定)\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.Y = torch.from_numpy(Y.astype(np.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f466926",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00159cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    def l2loss(pred, **sample):\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        return criterion(pred, sample[\"y\"])\n",
    "\n",
    "else:\n",
    "    #\n",
    "    l2loss = LpLoss(d=1, p=2, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b0d4e",
   "metadata": {},
   "source": [
    "# モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b9de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fno_model(n_modes=16, hidden_channels=64, n_layers=4, N_grid=64):\n",
    "    \"\"\"\n",
    "    1D FNO モデルを構築\n",
    "    \"\"\"\n",
    "    model = FNO(\n",
    "        n_modes=(n_modes,),     # 1次元なので tuple で (n_modes,)\n",
    "        hidden_channels=hidden_channels,\n",
    "        in_channels=6,\n",
    "        out_channels=1,\n",
    "        n_layers=n_layers,\n",
    "        max_n_modes=(N_grid,),  # グリッド数（通常は N）\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5023d",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c778d",
   "metadata": {},
   "source": [
    "データ読み込みと正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cf68b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 folders, loading 300 folders\n",
      "  loading... 0/300\n",
      "  loading... 50/300\n",
      "  loading... 100/300\n",
      "  loading... 150/300\n",
      "  loading... 200/300\n",
      "  loading... 250/300\n",
      "Done loading: torch.Size([900000, 6, 64]) torch.Size([900000, 1, 64])\n",
      "After normalization: X (900000, 6, 64) Y (900000, 1, 64)\n",
      "Dataset split: train=720000, val=90000, test=90000\n"
     ]
    }
   ],
   "source": [
    "# ---------- データ読み込み ----------\n",
    "X, Y = load_all_moments(root=root,max_cases=300)\n",
    "\n",
    "# ---------- 正規化 ----------\n",
    "X_norm, Y_norm = compute_and_apply_scaler(X, Y, save_path=\"scaler_random.npz\")\n",
    "print(\"After normalization: X\", X_norm.shape, \"Y\", Y_norm.shape)\n",
    "\n",
    "# ---------- Dataset & split ----------\n",
    "full_dataset = VlasovClosureDataset(X_norm, Y_norm)\n",
    "\n",
    "N_total = len(full_dataset)\n",
    "N_train = int(0.8 * N_total)\n",
    "N_val   = int(0.1 * N_total)\n",
    "N_test  = N_total - N_train - N_val\n",
    "\n",
    "train_ds, val_ds, test_ds = random_split(full_dataset, [N_train, N_val, N_test])\n",
    "print(f\"Dataset split: train={N_train}, val={N_val}, test={N_test}\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b357e12",
   "metadata": {},
   "source": [
    "モデル, optimizer, loss_fnの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "651e9631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNO(\n",
      "  (positional_embedding): GridEmbeddingND()\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x SpectralConv(\n",
      "        (weight): DenseTensor(shape=torch.Size([64, 64, 64]), rank=None)\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Flattened1dConv(\n",
      "        (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (channel_mlp): ModuleList(\n",
      "      (0-3): 4 x ChannelMLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,))\n",
      "          (1): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (channel_mlp_skips): ModuleList(\n",
      "      (0-3): 4 x SoftGating()\n",
      "    )\n",
      "  )\n",
      "  (lifting): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(7, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (projection): ChannelMLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(128, 1, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ---------- モデル構築 ----------\n",
    "N_grid = X.shape[-1]\n",
    "model = build_fno_model(\n",
    "    n_modes=16,\n",
    "    hidden_channels=64,\n",
    "    n_layers=4,\n",
    "    N_grid=N_grid\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# ---------- オプティマイザ・損失 ----------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55516c4b",
   "metadata": {},
   "source": [
    "学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a36bb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/10] train_loss=8.6597e-02, val_loss=6.8697e-02\n",
      "[02/10] train_loss=6.3800e-02, val_loss=6.2030e-02\n",
      "[03/10] train_loss=5.7051e-02, val_loss=5.5197e-02\n",
      "[04/10] train_loss=5.3307e-02, val_loss=5.2749e-02\n",
      "[05/10] train_loss=5.0848e-02, val_loss=5.0828e-02\n",
      "[06/10] train_loss=4.9055e-02, val_loss=4.9632e-02\n",
      "[07/10] train_loss=4.7635e-02, val_loss=4.8176e-02\n",
      "[08/10] train_loss=4.6497e-02, val_loss=4.7077e-02\n",
      "[09/10] train_loss=4.5599e-02, val_loss=4.6637e-02\n",
      "[10/10] train_loss=4.4833e-02, val_loss=4.5748e-02\n"
     ]
    }
   ],
   "source": [
    "# ---------- 学習ループ ----------\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)        # (B,3,N)\n",
    "        yb = yb.to(device)        # (B,1,N)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(xb)        # (B,1,N) を想定\n",
    "        loss = loss_fn(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # ---------- 検証 ----------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            y_pred = model(xb)\n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"[{epoch+1:02d}/{num_epochs}] train_loss={train_loss:.4e}, val_loss={val_loss:.4e}\")\n",
    "torch.save(model.state_dict(), \"FNOmodel_from_vlasov_random.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
